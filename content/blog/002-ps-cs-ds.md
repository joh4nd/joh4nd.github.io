---
title: "On the entanglement of domain interest, statistical analysis, data processing, and software engineering"
date: 2024-04-18T12:02:04+02:00
draft: false
---

- Having interest and domain knowledge.
- Statistical analysis of data.
- Instructing computers to process data.

These competencies are useful in tandem. And though their relative importance may shift, I believe the direction and the extent of this could be clearer.

10 years ago, Gary King explained that ["Big data" is actually not about the data](https://gking.harvard.edu/publications/preface-big-data-not-about-data). Big data is about what you do with it. It's about the analytics; making the data actionable. He flagged the economic calculous favoring statistical inference on data samples over managing distributed processing systems on data of whole populations. On the surface--but not when evaluating it a bit more in depth as I intend here--Gary's argument seems to weigh statistics and substantive knowledge higher than data or computer science. That's pretty much what political scientists like me are taught, which seems to suggest that we are all set and clear. At a time where chat-gpt has emerged and where many people are aware of "data science" and AI/ML's ability to crunch massive numbers, Gary's 10-year old point is provocative. People may even believe that one needs a data science degree to handle information technologies like programming, data analysis, predictive modelling. Considering the vast body of freely available materials for learning IT this is obviously mistaken, but there are other reasons too as I will show.

Gary's argument provoked me when I first read it in part because it is obviously true. Of course what matters is the quality of the decision that can be made based on the data rather than the data itself! Later it became clear to me that the data is an underlying confounder. In other words, if not the data is correct then forget about statistical inference. Everyone knows it: "garbage in, garbage out" (that's a reason why big data may make more problems than solutions). Yet, I've experienced that the data is in fact far more important than advanced statistical inference techniques and software. From that perspective the point **is** indeed the data (and some programming). But knowledge about statistical computations and reasoning about the domain I believe has enabled me to understand when data is problematic and needed engineering or wrangling to better inform business decisions. And that's a slightly different point!

In my opinion, the social sciences should more formally and extensively invite students to learn the parts of computer science that deal with getting the data right. To be sure, when doing projects the students do collect data and prepare it for analysis. But that's scratching the surface. Social science concepts are complex, which implies the data will be quite informative if gotten right. For instance, they could be introduced to the ways data can be processed and the infrastructure that enables this processing. Not least, with the post-millenium changes manifested in the Apache stack under the names of [Hadoop and Spark](https://www.oreilly.com/library/view/data-analytics-with/9780134844855/) (the setup Gary says is expensive) that I am currently reading about. Growing up in a household with IT such as www/networking, programming, and data processing; should I have assumed that those toys were for CS og DS degress only?! No, right? I don't think my opinion should be surprising because my way of thinking is not new at all (at least if you are oriented in science). Consider these fun facts:

- The teacher of the well-known [CS50](https://www.youtube.com/channel/UCcabW7890RKJzL968QWEykA) course, [David Malan](https://en.wikipedia.org/wiki/David_J._Malan), started out as undergraduate in political science (what is called Government at Harvard).
- In the 1960s, the java-based software named [Statistical Package for the Social Sciences](https://en.wikipedia.org/wiki/SPSS) was developed by political scientist [Norman Nie](https://news.stanford.edu/2015/05/08/norman-nie-obit-050815/) and a few of his CS friends.
- And, yes, Gary King himself is a great example.

Let's pick up the last bullet point. Look at what he has done to enable *data* to be shared in science. Big deal! He has also contributed to much statistical software and how to prepare data for analysis. He obviously jumps to the more (way more!) advanced inferential problems because he champions it all and has colleagues and students who knows how to get the data right. The more general point I believe is that as long as domain fields, computer science, and statistics have existed, individuals have naturally acquired competencies that span all three. They are more useful together than apart, and domain interest can also drive motivations to understand whether data, software, or a statistical method is problematic and needs a fix. 

Smart people out there are aware of the need to reconsolidate their discipline based on the overlaps addressed here and on the perceptions of what fields actually analyze data, process data, write software to analyze data, and so on. New programmes like "social data science" and "computational social science" shoot up next to the old ones that don't reform. The awkward silos may be torn down such that Python is no longer for IT and AI/ML folks (data science and computer science) while R is for applied statistics type domain fields (economics, sociology, psychology, business, biology, genomics, etc.).
